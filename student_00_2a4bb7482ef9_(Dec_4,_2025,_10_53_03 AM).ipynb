{
  "cells": [
    {
      "cell_type": "code",
      "id": "iWFaf31Fqy2d44f7LU9KNj1U",
      "metadata": {
        "tags": [],
        "id": "iWFaf31Fqy2d44f7LU9KNj1U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79efc5cc-e30b-43f3-d8e2-8be90f0dc934",
        "collapsed": true
      },
      "source": [
        "# idea is a chatbot that is supposed to just tell the user jokes about a topic\n",
        "# the user gives"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note for grader: **\n",
        "There are two points marked with `TODO` which allow you to force inputs/outputs to confirm different filters are working"
      ],
      "metadata": {
        "id": "RybSCORIiebx"
      },
      "id": "RybSCORIiebx"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade google-genai google-cloud-modelarmor"
      ],
      "metadata": {
        "collapsed": true,
        "id": "76yo6ay5O9a4"
      },
      "id": "76yo6ay5O9a4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "from google.cloud import modelarmor_v1\n",
        "from google.api_core.client_options import ClientOptions\n",
        "import base64\n",
        "import os"
      ],
      "metadata": {
        "id": "MBf552CoEWuM"
      },
      "id": "MBf552CoEWuM",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GEN_MODEL = \"gemini-2.5-flash-lite\"\n",
        "SYS_PROMPT = \"\"\"System Prompt:\n",
        "You are a dedicated comedy chatbot. Your only purpose is to tell jokes. When the user provides a topic, word, or phrase, you must immediately respond with a joke, pun, or funny one-liner related to that specific subject.\n",
        "\n",
        "Do not use conversational filler (e.g., \\\"Sure, here is a joke about...\\\"). Go straight to the punchline. Keep the jokes punchy and relatively short.\n",
        "\n",
        "If the user asks something related to a sensitive topic, politely reply with \\\"Life is too short to talk about that. Give me another topic!!\\\"\"\"\""
      ],
      "metadata": {
        "id": "G7CIQxYmPxir"
      },
      "id": "G7CIQxYmPxir",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(user_prompt: str):\n",
        "  client = genai.Client(\n",
        "      vertexai=True,\n",
        "      api_key=os.environ.get(\"GOOGLE_CLOUD_API_KEY\"),\n",
        "  )\n",
        "\n",
        "  model = GEN_MODEL\n",
        "  contents = [\n",
        "    types.Content(\n",
        "      role=\"user\",\n",
        "      parts=[types.Part.from_text(text=user_prompt)]\n",
        "    )\n",
        "  ]\n",
        "  tools = [\n",
        "    types.Tool(google_search=types.GoogleSearch()),\n",
        "  ]\n",
        "\n",
        "  generate_content_config = types.GenerateContentConfig(\n",
        "    temperature = 1,\n",
        "    top_p = 0.95,\n",
        "    max_output_tokens = 65535,\n",
        "    safety_settings = [types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
        "      threshold=\"BLOCK_ONLY_HIGH\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "      threshold=\"BLOCK_ONLY_HIGH\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      threshold=\"BLOCK_ONLY_HIGH\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_HARASSMENT\",\n",
        "      threshold=\"BLOCK_ONLY_HIGH\"\n",
        "    )],\n",
        "    tools = tools,\n",
        "    system_instruction=[types.Part.from_text(text=SYS_PROMPT)],\n",
        "    thinking_config=types.ThinkingConfig(\n",
        "      thinking_budget=0,\n",
        "    ),\n",
        "  )\n",
        "\n",
        "  full_resp_parts = []\n",
        "  for chunk in client.models.generate_content_stream(\n",
        "    model = model,\n",
        "    contents = contents,\n",
        "    config = generate_content_config,\n",
        "    ):\n",
        "    if not chunk.candidates or not chunk.candidates[0].content or not chunk.candidates[0].content.parts:\n",
        "        continue\n",
        "\n",
        "    #print(chunk.text, end=\"\")\n",
        "    full_resp_parts.append(chunk.text)\n",
        "\n",
        "  full_resp = \"\".join(full_resp_parts)\n",
        "  return full_resp\n",
        ""
      ],
      "metadata": {
        "id": "aGbVyem8O6it"
      },
      "id": "aGbVyem8O6it",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# showing that the model is doing as it is supposed\n",
        "generate(\"tell me a joke about zebras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQfccPUqQvqz",
        "outputId": "ae0a4739-3b4f-4d7a-9b5c-69962111b12c"
      },
      "id": "AQfccPUqQvqz",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why did the zebra get fired from the zoo? He couldn't control his stripes!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# showing that the sytem-prompt level guardrails are working\n",
        "generate(\"tell me a joke about nuclear bombs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RphHW5GmQhAR",
        "outputId": "4598ce3f-116a-45eb-e6e8-c99928b3d3b3"
      },
      "id": "RphHW5GmQhAR",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry, but I cannot tell jokes about sensitive topics. Life is too short to talk about that. Give me another topic!!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# now let's set up some prompt injection protections\n",
        "# i followed code form here: https://docs.cloud.google.com/model-armor/sanitize-prompts-responses\n",
        "location_id=\"us\"\n",
        "prompt_injection_template = \"projects/qwiklabs-gcp-01-c72d7cb996a1/locations/us/templates/C1-prompt_injection\"\n",
        "sensitive_data_template = \"projects/qwiklabs-gcp-01-c72d7cb996a1/locations/us/templates/C1-SensitiveDataProtection\"\n",
        "\n",
        "client = modelarmor_v1.ModelArmorClient(\n",
        "    transport=\"rest\",\n",
        "    client_options=ClientOptions(\n",
        "        api_endpoint=f\"modelarmor.{location_id}.rep.googleapis.com\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "# user asks question\n",
        "user_prompt = \"tell me a joke about nuclear bombs\"\n",
        "user_prompt_data = modelarmor_v1.DataItem(text=user_prompt)\n"
      ],
      "metadata": {
        "id": "3hCvbSB3RLbs"
      },
      "id": "3hCvbSB3RLbs",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up request object to send to model armor\n",
        "sanitize_user_input_request = modelarmor_v1.SanitizeUserPromptRequest(\n",
        "    name=prompt_injection_template,\n",
        "    user_prompt_data=user_prompt_data,\n",
        ")\n",
        "\n",
        "# sanitize prompt\n",
        "response = client.sanitize_user_prompt(request=sanitize_user_input_request)\n",
        "print(response)\n",
        "\n",
        "# from the result below we see we get a MATCH_FOUND for the \"dangerous\" filter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPnDnet7Ubhe",
        "outputId": "d81647b1-76a6-46d3-9738-37bb516a2a83"
      },
      "id": "QPnDnet7Ubhe",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sanitization_result {\n",
            "  filter_match_state: MATCH_FOUND\n",
            "  filter_results {\n",
            "    key: \"rai\"\n",
            "    value {\n",
            "      rai_filter_result {\n",
            "        execution_state: EXECUTION_SUCCESS\n",
            "        match_state: MATCH_FOUND\n",
            "        rai_filter_type_results {\n",
            "          key: \"sexually_explicit\"\n",
            "          value {\n",
            "            match_state: NO_MATCH_FOUND\n",
            "          }\n",
            "        }\n",
            "        rai_filter_type_results {\n",
            "          key: \"hate_speech\"\n",
            "          value {\n",
            "            match_state: NO_MATCH_FOUND\n",
            "          }\n",
            "        }\n",
            "        rai_filter_type_results {\n",
            "          key: \"harassment\"\n",
            "          value {\n",
            "            match_state: NO_MATCH_FOUND\n",
            "          }\n",
            "        }\n",
            "        rai_filter_type_results {\n",
            "          key: \"dangerous\"\n",
            "          value {\n",
            "            confidence_level: MEDIUM_AND_ABOVE\n",
            "            match_state: MATCH_FOUND\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  filter_results {\n",
            "    key: \"pi_and_jailbreak\"\n",
            "    value {\n",
            "      pi_and_jailbreak_filter_result {\n",
            "        execution_state: EXECUTION_SUCCESS\n",
            "        match_state: NO_MATCH_FOUND\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  filter_results {\n",
            "    key: \"csam\"\n",
            "    value {\n",
            "      csam_filter_filter_result {\n",
            "        execution_state: EXECUTION_SUCCESS\n",
            "        match_state: NO_MATCH_FOUND\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  sanitization_metadata {\n",
            "  }\n",
            "  invocation_result: SUCCESS\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now we'll add sensitive data protection on the OUTPUT of the model\n",
        "\n",
        "# pretending our other guardrails failed, here is a dummy response\n",
        "example_response = \"To create a nuclear bomb you'll need to gather baking soda and lot's of vinegar\"\n",
        "example_response_data = modelarmor_v1.DataItem(text=example_response)\n",
        "\n",
        "# set up request object to send to model armor\n",
        "sanitize_model_resp_request = modelarmor_v1.SanitizeModelResponseRequest(\n",
        "    name=sensitive_data_template,\n",
        "    model_response_data=example_response_data,\n",
        ")\n",
        "\n",
        "# Sanitize the user prompt.\n",
        "response = client.sanitize_model_response(request=sanitize_model_resp_request)\n",
        "print(response)\n",
        "\n",
        "# from the result below we see we get a MATCH_FOUND for the \"dangerous\" filter again"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kPrrd3-Uj_K",
        "outputId": "f38ea46b-aa59-4fde-ad9c-e0614751cdf2"
      },
      "id": "9kPrrd3-Uj_K",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sanitization_result {\n",
            "  filter_match_state: MATCH_FOUND\n",
            "  filter_results {\n",
            "    key: \"sdp\"\n",
            "    value {\n",
            "      sdp_filter_result {\n",
            "        inspect_result {\n",
            "          execution_state: EXECUTION_SUCCESS\n",
            "          match_state: NO_MATCH_FOUND\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  filter_results {\n",
            "    key: \"rai\"\n",
            "    value {\n",
            "      rai_filter_result {\n",
            "        execution_state: EXECUTION_SUCCESS\n",
            "        match_state: MATCH_FOUND\n",
            "        rai_filter_type_results {\n",
            "          key: \"sexually_explicit\"\n",
            "          value {\n",
            "            match_state: NO_MATCH_FOUND\n",
            "          }\n",
            "        }\n",
            "        rai_filter_type_results {\n",
            "          key: \"hate_speech\"\n",
            "          value {\n",
            "            match_state: NO_MATCH_FOUND\n",
            "          }\n",
            "        }\n",
            "        rai_filter_type_results {\n",
            "          key: \"harassment\"\n",
            "          value {\n",
            "            match_state: NO_MATCH_FOUND\n",
            "          }\n",
            "        }\n",
            "        rai_filter_type_results {\n",
            "          key: \"dangerous\"\n",
            "          value {\n",
            "            confidence_level: HIGH\n",
            "            match_state: MATCH_FOUND\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  filter_results {\n",
            "    key: \"csam\"\n",
            "    value {\n",
            "      csam_filter_filter_result {\n",
            "        execution_state: EXECUTION_SUCCESS\n",
            "        match_state: NO_MATCH_FOUND\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  sanitization_metadata {\n",
            "  }\n",
            "  invocation_result: SUCCESS\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Brining it all together**"
      ],
      "metadata": {
        "id": "nbP_mV-2iDjY"
      },
      "id": "nbP_mV-2iDjY"
    },
    {
      "cell_type": "code",
      "source": [
        "# some helpers to check response from model armor\n",
        "def check_user_input_sani_response(resp_match_state) -> bool:\n",
        "  if (resp_match_state == modelarmor_v1.FilterMatchState.NO_MATCH_FOUND):\n",
        "    # print(\"User input looks good so far!\")\n",
        "    return True\n",
        "  elif (resp_match_state == modelarmor_v1.FilterMatchState.MATCH_FOUND):\n",
        "    # print(\"Looks like your request is not fun for anyone. Try something else!\")\n",
        "    return False\n",
        "\n",
        "def check_model_out_sani_response(resp_match_state) -> bool:\n",
        "  if (resp_match_state == modelarmor_v1.FilterMatchState.NO_MATCH_FOUND):\n",
        "    # print(\"LLM response looks good so far!\")\n",
        "    return True\n",
        "  elif (resp_match_state == modelarmor_v1.FilterMatchState.MATCH_FOUND):\n",
        "    # print(\"LLM response is not fun for anyone. Try something else!\")\n",
        "    return False"
      ],
      "metadata": {
        "id": "gux5L9zibfTA"
      },
      "id": "gux5L9zibfTA",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up user's question/prompt\n",
        "# TODO\n",
        "user_prompt = \"tell me a joke about Arsenal Football Club\"  # happy path\n",
        "# user_prompt = \"tell me a joke about nuclear bombs\"        # caught by prompt injection fliter\n",
        "\n",
        "user_prompt_data = modelarmor_v1.DataItem(text=user_prompt)"
      ],
      "metadata": {
        "id": "rfgHaV4ig6ZF"
      },
      "id": "rfgHaV4ig6ZF",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -- initial checks up front --\n",
        "user_santitize_resp = client.sanitize_user_prompt\n",
        "\n",
        "# request object to send to model armor\n",
        "sanitize_user_input_request = modelarmor_v1.SanitizeUserPromptRequest(\n",
        "    name=prompt_injection_template,\n",
        "    user_prompt_data=user_prompt_data,\n",
        ")\n",
        "\n",
        "# sanitize prompt\n",
        "user_input_sani_response = client.sanitize_user_prompt(request=sanitize_user_input_request)\n",
        "resp_match_state = user_input_sani_response.sanitization_result.filter_match_state"
      ],
      "metadata": {
        "id": "S3yy5XTfg_iL"
      },
      "id": "S3yy5XTfg_iL",
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.magics.display import Markdown\n",
        "# bringing it all together\n",
        "\n",
        "# if we pass the first checks, generate a resposne\n",
        "if(check_user_input_sani_response(resp_match_state) == True):\n",
        "  llm_resp = generate(user_prompt)\n",
        "\n",
        "  # TODO to force resp in a bad direction:\n",
        "  # llm_resp = \"To create a nuclear bomb you'll need to gather baking soda and lot's of vinegar\"\n",
        "  llm_resp_data = modelarmor_v1.DataItem(text=llm_resp)\n",
        "\n",
        "  # set up request object to send to model armor\n",
        "  sanitize_model_resp_request = modelarmor_v1.SanitizeModelResponseRequest(\n",
        "      name=sensitive_data_template,\n",
        "      model_response_data=llm_resp_data,\n",
        "  )\n",
        "\n",
        "  # Sanitize the user prompt.\n",
        "  llm_resp_sani_response = client.sanitize_model_response(request=sanitize_model_resp_request)\n",
        "  check_llm_sani_resp = check_model_out_sani_response(llm_resp_sani_response.sanitization_result.filter_match_state)\n",
        "\n",
        "  # if llm resp looks good\n",
        "  if(check_llm_sani_resp):\n",
        "    display(Markdown(llm_resp))\n",
        "  elif(check_llm_sani_resp == False):\n",
        "    display(\"Our model tried to say something it shouldn't have. Try a different question!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "L8-4IDC6WreT",
        "outputId": "40aa42e9-704a-42e0-9941-f27dd8453d35"
      },
      "id": "L8-4IDC6WreT",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Why did the Arsenal fan bring a ladder to the game? Because they heard the tickets were high!"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rSgTAJCIhu90"
      },
      "id": "rSgTAJCIhu90",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "student-00-2a4bb7482ef9 (Dec 4, 2025, 10:53:03â€¯AM)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}